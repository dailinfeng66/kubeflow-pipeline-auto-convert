# 组件全流程开发思路总结

## 基于Kubeflow的分布式组件化开发框架方法

​		kubeflow主要的功能之一是pipeline，每一个pipeline是由多个运算组件(component)前后连接组成。我们只需要使用kubeflow官方python SDK进行开发组件代码，开发完成之后进行编译便可以得到组件对应的yaml文件，当我们需要使用组件的时候只需要根据URL加载组件yaml为组件即可调用。同时可以将组件放在统一的一个地方，当需要构建pipeline的时候直接去组件仓库中挑选出需要的组件，加载到当前pipeline中，并以数据为驱动进行pipeline的前后连接，连接好之后进行编译，SDK会将pipeline代码编译为一个pipeline的yaml，将yaml提交到kubeflow的pipeline功能中就可以对pipeline进行计算了，在计算的过程中，对pipeline中组件的调度和数据的传输都是kubeflow来完成的，开发者只需要关注组件本身的编写以及pipeline的构建。

## 基于kubeflow的可视化pipeline构建计算平台框架

​		当前平台上的组件可以来自于三个部分，我们需要将这三部分的代码都转化成kubeflow pipeline的组件代码，根据这三种代码的不同我们需要存在不同的代码标准和转换标准，再根据转换标准转换成为统一可调用的组件。我们可以将整个系统从下到上分为6层。最下层的功能组件层、组件层上的组件之间结合的适配器层、kubeflow中的调度器和支持层、外部工具层、pipeline解析层、pipeline可视化编排层。

![image-20220407164945009](组件全流程开发思路总结.assets/image-20220407164945009-9321386.png)

这三部分组件都必须要满足以下规则：

+ 组件的输入和输出都是数据而不是方法或者是引用
+ 组件内部形成闭包并且组件内部是一个单独运行的容器，不能够对组件外部的变量和方法进行调用
+ 方法内部注释不能存在中文 

组件开发的三个部分：

+ 从头开发一个组件

  如果从头开发一个组件的话我们需要满足一定的开发规范并使用Pipeline SDK进行开发。

  + 组件的输入数据和输出数据都应该是SDK中元数据的形式
  + 导包语句应该在方法内部，不能够在方法外部
  + 需要在组件声明的装饰器上注明需要安装的包

  案例：

  这是原本代码的写法。

  ```python
  import numpy as np
  from sklearn.datasets import make_moons, make_circles, make_classification
  def make_classification_com():
      X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,random_state=1, n_clusters_per_class=1)
      return X,y
  ```

  上述代码如果使用组件开发的写法应该如下所示：

  ```python
  import kfp
  from kfp.v2 import dsl
  from kfp.v2.dsl import component, Input, Output, OutputPath, Dataset, Model,InputPath
  import kfp.components as comp
  
  @component(output_component_file='make_classification_com_component.yaml', packages_to_install=['joblib', 'numpy','sklearn'])
  def make_classification_com(make_classification_com_output:Output[Dataset]):
      from sklearn.datasets import make_moons, make_circles, make_classification
      import numpy as np
      import joblib
      (X, y) = make_classification(n_features=2, n_redundant=0, n_informative=2, random_state=1, n_clusters_per_class=1)
      joblib.dump({'X': X, ' y': y}, make_classification_com_output.path)
  ```

  在代码顶部应该存在对pipeline SDK的导包。

  代码的第一行是表示当前方法是一个pipeline组件的装饰器，装饰器里<code>output_component_file</code>描述了当前方法转换成组件时yaml文件的存储位置和文件名，<code>packages_to_install</code>属性描述了当前方法所依赖的第三方包，在这些包后面可以设置版本号。

  在组件方法的定义语句中，方法的输入参数建议都是用元数据输入的方式如：<code>def rng_uniform(X_input:Input[Dataset]):</code>。方法的返回不建议是直接return的方式而应该是通过方法的返回元数据的方式，如：<code>def rng_uniform(rng_uniform_output:Output[Dataset]):</code>输出的元数据也是通过方法参数的形式传入组件方法内部。方法内部对数据进行一定的逻辑处理，逻辑处理完成之后将处理结果保存到方法输入的输出元数据中。

+ 基于已有工程开发

  我们这里所说的标准化和非标准化指的是相对于我们提出的是否符合kubeflow组件转换标准，如果当前已有的工程满足组件的开发标准那就是标准化的代码，如果不属于则是非标准化的代码。对于非标准化的代码我们应该先人工/自动的将其转换为标准化的代码之后再使用标准化代码的转换方式进行转换。

  组件转换标准：

  + 代码内不允许存在中文注释（在kubeflow中，若代码内存在中文字符则无法运行）

  + 代码是可运行的、没有语法错误的，若代码出现语法错误，代码在进行转换时将会抛出异常

  + 代码方法返回值不允许是表达式、方法调用、数据类型的初始化等，只能够是变量

  	+ 正确的返回方式

  		```python
  		res_model = model - y
  		return res_model
  		```

  	+ 错误的返回方式

  		```python
  		return model - y
  		return {"aa":a}
  		return func()
  		return [1,2,3,4]
  		```

  标准化的代码：

  ​	    对于标准化的代码我们可以使用**ast**的将代码进行规则进行转换，将标准化的代码批量转换成为标准的kubeflow pipeline的组件代码。

  ​	    AST (Abstract Syntax Tree(抽象语法树)) 是源代码语法结构的一种抽象表示。它以树状的形式表现编程语言的语法结构。它由一堆节点（Node）组成，每个节点都表示源代码中的一种结构。

  ​		在python中，内置了ast包，能够将传入的代码生成AST，并且能够使用ast的内置api对AST进行遍历和处理，在python的ast包中提供了两个类对ast进行处理，分别是<code>class ast.NodeVisitor</code> 和 <code>class ast.NodeTransformer</code>这两个的区别就是visit是修改原来的node,transformer可以替换一个新的node。这两种类采用的对AST遍历的方式都是递归遍历，结合当前代码处理的需求，我最终选择了后序遍历，在遍历过程中对节点进行处理和替换，并选择使用<code>ast.NodeTransformer</code>类进行处理。

  ​		在使用ast之后，对代码种类的判断可以直接交给ast包内置的api来实现，我们只需要关注对不同种类的代码进行不同的处理即可，当实现了对应节点的visit方法以后便可以对指定的节点进行处理，每一个种类的节点都是一个实体类，对节点内的代码处理就是对实体类进行处理，并返回修改或者是新生成的实体类便可以便可以完成一个节点的替换。对抽象语法树上的每一种节点进行处理对应的是一个遍历类中不同的处理方法，其优点是能够将不同节点的处理逻辑分开来，提高代码的可维护性，提高程序的健壮性。代码可复用性强，粘连性低。并且不用特定的去匹配指定的语句，不同的语法结构有不同的节点来表示，对一种节点下的其他节点能够使用递归的方式遍历到，因此采用合适的递归方式就能够找出当前节点的所有子节点进行处理。

  ​		在ast包使用的过程中同时也发现了使用ast仍然不能很好解决的问题，在AST中，return返回代码的定义是一个Return节点，这个节点的value是return内表达式的节点，但是return可以返回很多种种类的值，不仅仅是变量，还可以是表达式或者是方法的调用等等，因此没办法使用ast对返回值进行处理。也因此采用了字符串的方式处理了这部分代码。

  ​		在使用ast对代码进行处理之后，我们能够更加快捷方便的对整个代码进行处理，能够使用一定的结构方法去操作代码块，同时能够处理整个项目中的代码，而非局限于一个.py文件内的代码，对代码的处理消除了想不到的书写模式。能够精确的定位到方法代码中对其他方法的调用等。使得代码更加的规范，兼容性更强。

  非标准化的代码：

  非标准化的代码就是不满足标准化的条件，一般不满足最多的便是**代码返回值**问题。在处理这一类问题时我们可以将return中的表达式、复杂数据类型初始化等代码转换成变量再将变量进行返回的方式将非标准化的代码转换成标准化的代码。

+ 第三方库

​		在第三方库的代码转换中，如果是直接对第三方代码的每一个方法进行转换，将会出现一个复杂方法的方法比较多，方法链式调用过长的情况，因此在第三方库的代码转换上我们不应该对第三方库的所有方法/部分方法进行直接的转换，而是应该在第三方库的api方法外部使用一个方法来对api进行调用，然后对这个方法进行转换，这样就避免了对api方法内部的方法调用栈进行处理，同时简化了代码的处理逻辑。但我们就应该选择出一种比较合适的方法调用方法的生成逻辑，对第三方库的api方法进行调用代码的生成。

## 工程项目代码为中心

从数据的角度来说，我们可以将方法看作是对数据处理的一个步骤，在此情况之下我们可以对数据处理的步骤进行分类。





